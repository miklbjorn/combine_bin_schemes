{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizing binning schemes 1: Optimising for stand-alone measurement?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from combine_bins import test_F_1 as F\n",
    "from combine_bins import test_c_1 as c\n",
    "from combine_bins import Amp_p\n",
    "\n",
    "Ap = Amp_p(F, c, 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from combine_bins.util import get_F_c\n",
    "from combine_bins import BinnedFitter \n",
    "import combine_bins.binnings as binnings\n",
    "\n",
    "simple_binning = binnings.simple_binning\n",
    "equal_binning = binnings.approx_equal_binning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import autograd.numpy as np\n",
    "\n",
    "def Q(amp, binning, x=0):\n",
    "    Fs, cs = get_F_c(amp, binning)\n",
    "    bf = BinnedFitter(binning, Fs, cs)\n",
    "    N = bf.predict_yields(x, 1000)\n",
    "    dN = bf.predict_dN_dx(x, 1000)\n",
    "    return np.sqrt( np.sum((dN/np.sqrt(N)) **2) / (sum(N)*amp.sensitivity(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q_simple = Q(Ap, simple_binning, 0.3)\n",
    "Q_equal = Q(Ap, equal_binning, 0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does the factor $Q$ reproduces $1/\\sigma_x$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results from the simple studies\n",
    "mean_cont = 0.015744444629682317\n",
    "mean_simple = 0.01936067469619681\n",
    "mean_equal = 0.02063644527315257"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "continuous sigma ratio: 0.813 vs Q: 0.905\n",
      "continuous sigma ratio: 0.763 vs Q: 0.881\n",
      "bin vs bin sigma ratio: 1.066 vs Q: 1.027\n"
     ]
    }
   ],
   "source": [
    "print (f'continuous sigma ratio: {mean_cont/mean_simple:1.3f} vs Q: {Q_simple:1.3f}')\n",
    "print (f'continuous sigma ratio: {mean_cont/mean_equal:1.3f} vs Q: {Q_equal:1.3f}')\n",
    "print (f'bin vs bin sigma ratio: {mean_equal/mean_simple:1.3f} vs Q: {Q_simple/Q_equal:1.3f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So it does not seem like the ratios are produced exactly, but it does look like the **ordering** is correct, and hence $Q$ is tool that can be used in binning-scheme optimisation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making an optimized binning scheme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimising binning scheme 2: choosing optimal binning schemes *to combine*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final measure to optimise is of course the combined $\\sigma_x$. Can we find some proxy variable, like $Q$ is for the single-binning scheme, which avoids spending ages on toy studies?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
